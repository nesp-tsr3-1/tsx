= TSX User Guide (Simplified)
James Watmuff <james@planticle.com.au>; Elisa Bayraktarov <tsx@uq.edu.au>
:description: This guide describes how to install, setup and run the Threatened Species Index (TSX).
:doctype: book
:page-layout!:
:toc: left
:toclevels: 2
:sectanchors:
:sectlinks:
:sectnums:
:icons: font
:source-highlighter: coderay
:source-language: asciidoc
:experimental:
:stem:
:idprefix:
:idseparator: -
:ast: &ast;
:dagger: pass:normal[^&dagger;^]
:endash: &#8211;
:y: icon:check[role="green"]
:n: icon:times[role="red"]
:c: icon:file-text-o[role="blue"]
:table-caption!:
:example-caption!:
:figure-caption!:
:imagesdir: images
:includedir: _includes
:underscore: _
:adp: AsciiDoc Python
:adr: Asciidoctor

// Refs
:uri-home: https://tsx.org.au
:uri-github: https://github.com/nesp-tsr3-1/tsx
:uri-full-guide: https://tsx.org.au/user-guide

NOTE: If you find errors or omissions in this document, please don't hesitate to {uri-github}/issues[submit an issue].

= Introduction

== What is the TSX?

The TSX is the world’s first Threatened Species Index. It will do for Australia’s threatened species what the ASX does for Australia’s stock market. The TSX comprises a set of indices that provide reliable and robust measures of population trends across Australia’s threatened species. It will allow users to look at threatened species trends, for all of Australia and all species altogether, or for individual regions or groups, for example migratory birds. This will enable more coherent and transparent reporting of changes in biodiversity at national, state and regional levels. The index constitutes a multi-species composite index calculated from processed and quality controlled Australian threatened and near-threatened species time-series data based on the Living Planet Index (Collen et al. 2009) approach. The Living Planet Index method requires input on species population data repeatedly recorded for a species at a survey site carried out with the same monitoring method quantifying the same unit of measurement and aggregated from raw data into a yearly time series through time. This guide exemplifies how to use an automated processing workflow pipeline to streamline all processing steps required to convert raw species population data into consistent time series for the calculation of composite multi-species trends.

== How to use this guide

This guide documents the easiest way to run the TSX workflow to produce a Living Planet Index trend based on raw observation data. For a more detailed and technical guide covering advanced processing options and a variety of installation methods, please see the {uri-full-guide}[full guide].

== Workflow Concepts

The TSX is produced using a workflow that begins with raw observation data collated into a relational database in a standardised way. These data are processed into time series that ultimately produce the index as well as diagnostics that provide additional context. The overall structure of the workflow is illustrated below.

image::workflow-overview.png[Workflow Overview,400]

This simplified guide will not make use of the auxiliary data and suitability criteria filtering components illustrated above. For more information about these components, see the {uri-full-guide}[full guide].

== Architecture

The data import, pre-processing and filtering steps are performed using Python scripts that operate on a relational MySQL database. The last step of Living Planet Index calculation is performed using an R script, which operates on a CSV file that is produced by preceding steps of the workflow. This is illustrated below.

image::workflow-implementation.png[Workflow Architecture,600]

A web interface can be used to import data and view the generated indices, diagnostics and processed data. This is not an essential element of the workflow and is not covered in this guide.

= Installation and Setup

== System requirements

The TSX workflow can run on Windows, macOS or Linux. 8GB RAM and 4GB available storage space is recommended.

== Installation

include::include/install-virtualbox.adoc[]

= Running the workflow

== Open Jupyter Lab

Once you have started the virtual machine, you should see a window containing the message:

----
Open Jupyter Lab by visiting this URL in your web browser:

http://xxx.xxx.xxx.xxx:8888
----

Please open this url using any web browser installed on your computer.

NOTE: To copy text out of the VirtualBox window, the keyboard shortcut is kbd:[Shift+Ctrl+C]. If you encounter problems with copying and pasting the URL, it may be easier to manually type it out instead.

After opening the URL, you should see the following interface in your web browser:

image::jupyter-start.png[Jupyter Lab,600]

== Data Import

Raw observation data may now be imported into the database. Some sample data can be found in `sample-data/type_1_sample.csv`.

Feel free to locate this file in the `sample-data` folder using the file browser in Jupyter Lab. You can view the file contents inside Jupyter Lab, or alternatively download it to and open it with a spreadsheet program. You may wish to use it as a template for importing your own observation data. You can upload your own data files to Jupyter Lab by clicking the upload icon at the top of the file browser window.

To import the observation data, first open a terminal in Jupyter Lab by selecting `File` > `New` > `Terminal`.

Then, run the following command:

----
python -m tsx.importer --simple -c sample-data/type_1_sample.csv
----

If you wish to import your own observation data that you have uploaded to Jupyter Lab, change the filename in the command above accordingly.

The import process will run a range of checks on the imported data, which will generate warnings and/or errors. Warnings are advisory, while errors will prevent the data from being imported until they are fixed. This helps to ensure data quality.

After the import process has completed successfully, you should see output that looks like this:

----
(env) tsx@tsx:~/tsx$ python -m tsx.importer --simple -c sample-data/type_1_sample.csv
2020-11-20 02:38:42,996 INFO     Starting import
2020-11-20 02:38:42,998 INFO     File format: CSV
100%|##############################| 253/253 [00:10<00:00, 25.18it/s]
2020-11-20 02:38:53,076 INFO     Committing changes
2020-11-20 02:38:53,080 INFO     Processed 253/253 rows
2020-11-20 02:38:53,081 INFO     Import processing complete. Errors: 0, Warnings: 0
----

NOTE: If you wish to delete data that you have imported so far and start again, see <<Starting afresh>>.

== Data Processing

The next step is to run the workflow on this imported data.

In the Jupyter Lab terminal, run the following command:

----
python -m tsx.process -c simple
----

For the sample dataset, this processing should complete very quickly, with output like this:

----
(env) tsx@tsx:~/tsx$ python -m tsx.process -c simple
2020-11-20 02:47:52,534 INFO     STEP 0 - CLEARING PREVIOUS RESULTS
100%|##############################| 10/10 [00:00<00:00, 148.39it/s]
2020-11-20 02:47:52,605 INFO     STEP 1 - TYPE 1 DATA AGGREGATION
2020-11-20 02:47:52,607 INFO     Step 1/2: Monthly aggregation
100%|##############################| 3/3 [00:00<00:00,  4.24it/s]
2020-11-20 02:47:53,317 INFO     Step 2/2: Yearly aggregation
100%|##############################| 3/3 [00:00<00:00,  5.26it/s]
2020-11-20 02:47:53,891 INFO     STEP 2 - EXPORT
2020-11-20 02:47:53,894 INFO     Generating numeric IDs
2020-11-20 02:47:53,898 INFO     Calculating region centroids
2020-11-20 02:47:53,901 INFO     Exporting LPI wide table file: /home/tsx/tsx/sample-data/export/lpi.csv
100%|##############################| 3/3 [00:00<00:00, 97.18it/s]
2020-11-20 02:47:53,935 INFO     Done
2020-11-20 02:47:53,936 INFO     PROCESSING COMPLETE
----

The workflow has now completed processing all raw observation data in the database to produce aggregated time series in the file `sample-data/export/lpi.csv`. This file is in a format ready for processing using the Living Planet Index method.

== Living Planet Index Calculation

The Living Planet Index R package, https://github.com/Zoological-Society-of-London/rlpi[`rlpi`], is used to generate the main final output of the TSX workflow.

To make this easier, we have created a Jupyter notebook that runs this final step. Using the Jupyter Lab file browser, go to the `r` directory and double click on the `lpi.ipynb` notebook file. It should look like this:

image::jupyter-r-notebook.png[Jupyter Notebook for running LPI calculation using R]

Use the play icon at the top of the notebook tab to run through each step.

You should be rewarded with a plot and table showing the resulting TSX index:

(TODO)

Congratulations!

== Starting afresh

If you have been working through this guide using the sample observation data, and now wish to start again using your own observation data, first clear out the database by running the following command in the Jupyter Lab terminal:

----
cat data/sql/create.sql data/sql/init.sql | mysql tsx
----

NOTE: If you get stuck, you can get in touch by {uri-github}/issues[submitting an issue here].

For further information about running the TSX workflow, check out the {uri-full-guide}[full guide].
